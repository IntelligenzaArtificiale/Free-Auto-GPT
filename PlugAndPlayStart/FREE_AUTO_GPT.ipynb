{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WWnigaEo63W0",
        "k5YdBQWu7eWw",
        "MhiskJ9nJtNC",
        "UnP0gaxW9SBY",
        "H_aNlq64ANbf",
        "9y5lqAosD6xc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#USE AI AGENTs, like AUTOGPT or BABYAGI, without paids API. TOTALLY FOR FREE ğŸ"
      ],
      "metadata": {
        "id": "IAnBqnxo2CkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![AUTO GPT FREE](https://github.com/IntelligenzaArtificiale/Free-AUTO-GPT-with-NO-API/raw/main/img/GH2.gif)"
      ],
      "metadata": {
        "id": "bMpPiTwk2vRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETUP REPOSITORY ğŸ“‚\n"
      ],
      "metadata": {
        "id": "WWnigaEo63W0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Me-TEdpy1-Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c41191-1f44-4700-b7c1-588d96a62a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Free-AUTO-GPT-with-NO-API'...\n",
            "remote: Enumerating objects: 579, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 579 (delta 130), reused 168 (delta 91), pack-reused 322\u001b[K\n",
            "Receiving objects: 100% (579/579), 35.33 MiB | 33.81 MiB/s, done.\n",
            "Resolving deltas: 100% (282/282), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IntelligenzaArtificiale/Free-AUTO-GPT-with-NO-API.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Free-AUTO-GPT-with-NO-API/requirements.txt \n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npyZzszN7MhH",
        "outputId": "c3cda6ab-5f89-499b-e3a4-141cd204f7ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (2.27.1)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.152-py3-none-any.whl (666 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m666.9/666.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-chat-media\n",
            "  Downloading streamlit_chat_media-0.0.4-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 5)) (1.22.4)\n",
            "Collecting retry\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting revChatGPT\n",
            "  Downloading revChatGPT-5.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-2.8.6-py3-none-any.whl (30 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 10)) (0.8.10)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (6.0)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (1.10.7)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>1.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (2.0.10)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (2.8.4)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (8.2.2)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (23.1)\n",
            "Collecting validators>=0.2\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (6.2)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (9.0.0)\n",
            "Collecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (4.2.2)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (8.4.0)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (8.1.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (5.3.0)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (1.5.3)\n",
            "Collecting blinker>=1.0.0\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (13.3.4)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (6.6.0)\n",
            "Collecting py<2.0.0,>=1.4.26\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 6)) (4.4.2)\n",
            "Collecting tiktoken>=0.3.0\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting OpenAIAuth==0.3.6\n",
            "  Downloading OpenAIAuth-0.3.6-py3-none-any.whl (4.5 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[socks]\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-tio\n",
            "  Downloading async_tio-1.3.2-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from revChatGPT->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 7)) (3.0.38)\n",
            "Collecting requests\n",
            "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 9)) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 9)) (3.12.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 11)) (4.11.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.12.0)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 9)) (2023.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>1.3->langchain->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.1.0.post0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->revChatGPT->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 7)) (1.3.0)\n",
            "Collecting httpcore<0.18.0,>=0.15.0\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting socksio==1.*\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit->revChatGPT->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 7)) (0.2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 1)) (1.7.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx[socks]->revChatGPT->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 7)) (3.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->-r /content/Free-AUTO-GPT-with-NO-API/requirements.txt (line 3)) (2023.3)\n",
            "Building wheels for collected packages: wikipedia, validators\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=9b9f8b0b02523aa77a8f9dc8d325be621fabfcc9784335ea2d434c338593afd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=e1d93deac1615b1a288b42dac5b0cb5bf31395969d687d1b505d12a98cd239ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built wikipedia validators\n",
            "Installing collected packages: tokenizers, watchdog, validators, socksio, smmap, requests, pympler, py, mypy-extensions, multidict, marshmallow, h11, frozenlist, blinker, async-timeout, yarl, wikipedia, typing-inspect, tiktoken, retry, pydeck, openapi-schema-pydantic, OpenAIAuth, marshmallow-enum, huggingface-hub, httpcore, gitdb, duckduckgo-search, aiosignal, transformers, httpx, gitpython, dataclasses-json, aiohttp, streamlit, openai, langchain, async-tio, streamlit-chat-media, revChatGPT\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "Successfully installed OpenAIAuth-0.3.6 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 async-tio-1.3.2 blinker-1.6.2 dataclasses-json-0.5.7 duckduckgo-search-2.8.6 frozenlist-1.3.3 gitdb-4.0.10 gitpython-3.1.31 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.14.1 langchain-0.0.152 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.5 openapi-schema-pydantic-1.2.4 py-1.11.0 pydeck-0.8.1b0 pympler-1.0.1 requests-2.29.0 retry-0.9.2 revChatGPT-5.0.0 smmap-5.0.0 socksio-1.0.0 streamlit-1.22.0 streamlit-chat-media-0.0.4 tiktoken-0.3.3 tokenizers-0.13.3 transformers-4.28.1 typing-inspect-0.8.0 validators-0.20.0 watchdog-3.0.0 wikipedia-1.4.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HOW TO GET CHATGPT & HUGGINGFACE TOKEN FREE ğŸ’¡\n",
        " "
      ],
      "metadata": {
        "id": "k5YdBQWu7eWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- HUGGINGFACE  : Visit this simple [official guide](https://huggingface.co/docs/hub/security-tokens)\n",
        "- CHATGPT : visit this [site](https://chat.openai.com/api/auth/session) and copy the \"accessToken\"\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/108482353/234968090-b724e277-566c-4e42-9936-7592043f70fa.png)\n",
        "\n",
        "**SAVE only your token, without anything else.**"
      ],
      "metadata": {
        "id": "Ia_ZQWBi7u1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸš€SAVE HERE YOURS TOKENsğŸš€\n",
        "\n",
        "**HuggingFACE TOKEN** : _YOURtOkEN_\n",
        "\n",
        "\n",
        "**CHATGPT TOKEN** : _YOURtOkEN-is-SO-LOnG_"
      ],
      "metadata": {
        "id": "ZJ5uN73z8W5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN BABYAGI ğŸ‘¶"
      ],
      "metadata": {
        "id": "MhiskJ9nJtNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Open the /content/Free-AUTO-GPT-with-NO-API/BABYAGI.py and Set \"verbose=True\" for view the debug \n",
        "\n",
        "!python /content/Free-AUTO-GPT-with-NO-API/BABYAGI.py --hf_token YourToken --chatgpt_token YourToken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d2efee-c27d-4062-bf98-f0818b9a058a",
        "id": "LzZ5l0wHJtNe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain.vectorstores.faiss.FAISS object at 0x7f738e8ee560>\n",
            "Enter the maximum number of iterations: (Suggest from 3 and 5) 5\n",
            "Enter the objective of the AI system: (Be realistic!) Write me a plan for create a Startup about AI agent capable of performing tasks.\n",
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Make a todo list\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Make a todo list\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "Sure, here's a todo list for creating a startup about an AI agent capable of performing tasks:\n",
            "\n",
            "1. Define the problem your AI agent will solve: Identify the specific tasks that your AI agent will be capable of performing, and the target audience who will benefit from it.\n",
            "\n",
            "2. Research the market: Determine the competition in your target market and understand their strengths and weaknesses.\n",
            "\n",
            "3. Develop a business plan: Create a plan that outlines your vision, mission, goals, strategies, budget, and revenue model.\n",
            "\n",
            "4. Build a team: Find experienced professionals who have the skills and expertise to develop and market your AI agent.\n",
            "\n",
            "5. Create a prototype: Develop a working prototype of your AI agent that can perform the tasks you identified in step 1.\n",
            "\n",
            "6. Test and refine your AI agent: Continuously test and improve your AI agent to make sure it can perform its tasks effectively and efficiently.\n",
            "\n",
            "7. Build a brand: Develop a brand identity and marketing strategy that aligns with your target audience and communicates the benefits of your AI agent.\n",
            "\n",
            "8. Launch your startup: Launch your AI agent to the market and use feedback to refine and improve your product.\n",
            "\n",
            "9. Continuously innovate: Keep up with the latest advancements in AI technology and continuously innovate to stay ahead of the competition.\n",
            "\n",
            "10. Monitor performance and growth: Continuously monitor the performance and growth of your startup, and make necessary adjustments to ensure success.\n",
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "2: Determine the technical requirements needed to build your AI agent, including hardware and software components, and identify potential suppliers and vendors.\n",
            "1: Conduct a market analysis to identify potential target audiences for your AI agent, and determine their specific needs and pain points.\n",
            "3: Develop a comprehensive user interface and experience design that is intuitive and easy to use, and that maximizes the efficiency and effectiveness of your AI agent.\n",
            "4: Conduct rigorous testing and quality assurance checks to ensure that your AI agent is reliable, accurate, and secure, and that it can perform its tasks consistently and without error.\n",
            "8: Build a strong team of employees and advisors who have the skills and expertise needed to bring your AI agent to market, and who are passionate about the potential of AI to transform industries and improve people's lives.\n",
            "5: Establish partnerships and collaborations with other companies and organizations in the AI space to leverage their expertise and resources, and to stay up-to-date with the latest developments in the field.\n",
            "7: Secure funding and investment from investors and venture capitalists, and develop a financial plan that includes revenue projections, cost estimates, and funding requirements.\n",
            "6: Develop a robust marketing and sales strategy that targets potential customers and partners, and that showcases the unique value proposition of your AI agent.\n",
            "9: Establish a strong ethical framework for your AI agent, and ensure that it is developed and deployed in a responsible and transparent manner that respects privacy, security, and human rights.\n",
            "10: Develop a comprehensive training and support program for users of your AI agent, including online tutorials, technical support, and user forums.\n",
            "Note that the original task list was not modified or removed, only reordered based on the priority and relevance to the ultimate objective of the team: \n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "2: Determine the technical requirements needed to build your AI agent, including hardware and software components, and identify potential suppliers and vendors.\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "Sure, here's a plan for determining the technical requirements needed to build your AI agent:\n",
            "\n",
            "1. Identify the specific tasks your AI agent will perform: Determine the functions and capabilities that your AI agent will need to have in order to perform the tasks you've identified.\n",
            "\n",
            "2. Determine the hardware requirements: Identify the hardware components that your AI agent will need in order to function, such as processors, memory, and storage.\n",
            "\n",
            "3. Determine the software requirements: Identify the software components that your AI agent will need in order to operate, such as machine learning algorithms, programming languages, and development tools.\n",
            "\n",
            "4. Research potential suppliers and vendors: Identify potential suppliers and vendors for the hardware and software components you'll need, and evaluate their offerings in terms of cost, quality, and compatibility with your AI agent.\n",
            "\n",
            "5. Evaluate cloud-based vs. on-premise solutions: Consider whether your AI agent will be deployed in the cloud or on-premise, and evaluate the pros and cons of each approach.\n",
            "\n",
            "6. Consider scalability and future growth: Ensure that the technical requirements you identify are scalable and can support future growth of your AI agent.\n",
            "\n",
            "7. Determine the technical skills needed: Identify the technical skills and expertise that your development team will need in order to build and maintain your AI agent, and assess whether you have the necessary resources in-house or if you need to hire additional talent.\n",
            "\n",
            "8. Develop a technology roadmap: Create a roadmap that outlines the timeline and milestones for acquiring and implementing the necessary hardware and software components, and ensure that it aligns with your overall business plan and budget.\n",
            "\n",
            "By completing these tasks, you will have a clear understanding of the technical requirements needed to build your AI agent, as well as potential suppliers and vendors to work with to acquire the necessary components.\n",
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Conduct a market analysis to identify potential target audiences for your AI agent, and determine their specific needs and pain points.\n",
            "2: Develop a comprehensive user interface and experience design that is intuitive and easy to use, and that maximizes the efficiency and effectiveness of your AI agent.\n",
            "3: Conduct rigorous testing and quality assurance checks to ensure that your AI agent is reliable, accurate, and secure, and that it can perform its tasks consistently and without error.\n",
            "4: Build a strong team of employees and advisors who have the skills and expertise needed to bring your AI agent to market, and who are passionate about the potential of AI to transform industries and improve people's lives.\n",
            "5: Establish partnerships and collaborations with other companies and organizations in the AI space to leverage their expertise and resources, and to stay up-to-date with the latest developments in the field.\n",
            "6: Secure funding and investment from investors and venture capitalists, and develop a financial plan that includes revenue projections, cost estimates, and funding requirements.\n",
            "7: Develop a robust marketing and sales strategy that targets potential customers and partners, and that showcases the unique value proposition of your AI agent.\n",
            "8: Establish a strong ethical framework for your AI agent, and ensure that it is developed and deployed in a responsible and transparent manner that respects privacy, security, and human rights.\n",
            "9: Develop a comprehensive training and support program for users of your AI agent, including online tutorials, technical support, and user forums.\n",
            "10: Develop a proof of concept for your AI agent to demonstrate its capabilities to potential customers and investors. This should include a demo of the agent performing its designated tasks.\n",
            "11: Conduct a feasibility analysis to determine the technical, financial, and legal feasibility of building and deploying your AI agent. This should include an analysis of the market demand for your agent, as well as the regulatory and legal requirements for AI development and deployment.\n",
            "12: Develop a data strategy for your AI agent that includes data acquisition, storage, cleaning, and analysis. This should include a plan for how you will collect and manage the data needed to train and improve your AI agent.\n",
            "13: Develop a security strategy for your AI agent that includes data privacy, encryption, and cybersecurity. This should include a plan for how you will protect your AI agent from potential security threats and breaches.\n",
            "14: Develop an integration strategy for your AI agent that includes integration with existing systems and platforms. This should include a plan for how you will integrate your AI agent with other software and hardware components to create a seamless user experience.\n",
            "15: Develop a performance monitoring and optimization strategy for your AI agent that includes metrics for measuring performance, identifying areas for improvement, and optimizing the agent's performance over time.\n",
            "16: Develop a pricing strategy for your AI agent that is competitive and reflects the value it provides to customers. This should include a plan for how you will price your AI agent based on its capabilities and the needs of your target audience.\n",
            "17: Develop a customer support strategy for your AI agent that includes technical support, user training, and customer feedback channels. This should include a plan for how you will provide ongoing support to customers and incorporate their feedback into future product updates.\n",
            "18: Develop a roadmap for future development and growth of your AI agent that includes new features, capabilities, and target markets. This should include a plan for how you will continue to innovate and evolve your AI agent to meet the changing needs of your customers and the market.\n",
            "As the ultimate objective of the team is to create a startup about AI agent capable of performing tasks, the above tasks are necessary to ensure the successful development, deployment, and growth of the AI agent in the market: Each task is essential in its own right and cannot be ignored, and together they form a comprehensive plan that covers all aspects of creating and launching a successful AI agent.\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Conduct a market analysis to identify potential target audiences for your AI agent, and determine their specific needs and pain points.\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "Task 1: Make a to-do list\n",
            "Task 2: Determine the technical requirements needed to build your AI agent, including hardware and software components, and identify potential suppliers and vendors.\n",
            "Task 3: Conduct a market analysis to identify potential target audiences for your AI agent, and determine their specific needs and pain points.\n",
            "\n",
            "To conduct a market analysis, the following steps should be taken:\n",
            "\n",
            "1. Identify the industry and sector where your AI agent could be useful, such as healthcare, finance, or customer service.\n",
            "\n",
            "2. Research potential competitors in the market, including their strengths and weaknesses, pricing, and target audiences.\n",
            "\n",
            "3. Identify potential target audiences and their specific needs and pain points. This could include businesses or individuals who need to automate certain tasks or processes, or who want to improve their efficiency and productivity.\n",
            "\n",
            "4. Analyze market trends and forecasts to determine the potential demand for your AI agent in the coming years.\n",
            "\n",
            "5. Identify potential challenges and barriers to entry, such as regulatory requirements, technical barriers, or competition from established players in the market.\n",
            "\n",
            "6. Use the insights gained from the market analysis to refine the features and capabilities of your AI agent to better meet the needs of your target audience.\n",
            "\n",
            "By conducting a thorough market analysis, you can gain a better understanding of your target audience and their specific needs and pain points, which will enable you to create an AI agent that is better suited to their needs and more likely to succeed in the market.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/BABYAGI.py\", line 65, in <module>\n",
            "    baby_agi({\"objective\": OBJECTIVE})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 116, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 113, in __call__\n",
            "    outputs = self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/experimental/autonomous_agents/baby_agi/baby_agi.py\", line 136, in _call\n",
            "    self.vectorstore.add_texts(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/faiss.py\", line 128, in add_texts\n",
            "    embeddings = [self.embedding_function(text) for text in texts]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/faiss.py\", line 128, in <listcomp>\n",
            "    embeddings = [self.embedding_function(text) for text in texts]\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/Embedding/HuggingFaceEmbedding.py\", line 38, in newEmbeddingFunction\n",
            "    embeddings = newEmbeddings(texts)\n",
            "  File \"<decorator-gen-2>\", line 2, in newEmbeddings\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/retry/api.py\", line 73, in retry_decorator\n",
            "    return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/retry/api.py\", line 33, in __retry_internal\n",
            "    return f()\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/Embedding/HuggingFaceEmbedding.py\", line 33, in newEmbeddings\n",
            "    raise RuntimeError(\n",
            "RuntimeError: The model is currently loading, please re-run the query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN Meta-Prompt ğŸ‘¥"
      ],
      "metadata": {
        "id": "UnP0gaxW9SBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/Free-AUTO-GPT-with-NO-API/MetaPrompt.py --chatgpt_token YourToken\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA0gJrtI7tyW",
        "outputId": "e0b5d6e7-b803-4e15-d00f-9adf215a44f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the objective of the AI system: (Be realistic!) write a detalied plan to solve world hunger\n",
            "Enter the maximum number of interactions per episode: 2\n",
            "Enter the maximum number of episodes: 3\n",
            "[Episode 1/3]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Instructions: None\n",
            "    \n",
            "    Human: write a detalied plan to solve world hunger\n",
            "    Assistant:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "(Step 1/2)\n",
            "Assistant: Solving world hunger is a complex issue that requires a multi-faceted approach. Here is a detailed plan that can help address this problem:\n",
            "\n",
            "1. Increase Agricultural Productivity: This involves increasing the amount of food that is produced globally. To achieve this, there should be more investments in agriculture, research and development, and education to teach farmers about modern agricultural practices, such as irrigation, crop rotation, and use of improved seeds and fertilizers. This would lead to a greater yield of food from the same amount of land.\n",
            "\n",
            "2. Encourage Sustainable Farming Practices: Another way to increase agricultural productivity is to promote sustainable farming practices. Sustainable agriculture practices include the use of organic fertilizers, natural pest control, and water conservation methods. These practices not only increase productivity but also protect the environment.\n",
            "\n",
            "3. Improve Infrastructure: Poor infrastructure such as lack of roads, storage facilities, and irrigation systems can lead to food waste and limited access to food for people in remote areas. To address this, there should be investments in infrastructure to improve the transportation and storage of food, especially in developing countries.\n",
            "\n",
            "4. Reduce Food Waste: Around one-third of the food produced globally is wasted. To reduce this, there should be better management of food supply chains, such as reducing spoilage during transportation and storage. In addition, consumers should be educated about reducing food waste at home through practices such as proper food storage, meal planning, and composting.\n",
            "\n",
            "5. Address Climate Change: Climate change is one of the biggest threats to food security. It leads to changes in weather patterns, droughts, and floods, which can negatively impact food production. Addressing climate change through policies such as reducing greenhouse gas emissions, planting trees, and promoting renewable energy can help protect food security.\n",
            "\n",
            "6. Address Poverty: Poverty is a major cause of hunger, especially in developing countries. Addressing poverty through policies such as providing economic opportunities, education, and social welfare programs can help reduce hunger.\n",
            "\n",
            "7. Promote Fair Trade: Fair trade ensures that farmers in developing countries receive a fair price for their produce, which can help reduce poverty and hunger.\n",
            "\n",
            "8. Provide Emergency Food Aid: In cases of emergencies such as natural disasters and conflicts, providing emergency food aid can help save lives. Governments, NGOs, and international organizations should work together to provide emergency food aid when necessary.\n",
            "\n",
            "9. Encourage Education: Education is key to addressing hunger in the long term. Educating people about nutrition, healthy eating habits, and sustainable farming practices can help reduce hunger.\n",
            "\n",
            "10. Increase Awareness: Finally, raising awareness about hunger and its causes is crucial. Governments, NGOs, and international organizations should work together to raise awareness about hunger and promote action to address this issue.\n",
            "\n",
            "Overall, solving world hunger requires a comprehensive approach that addresses the underlying causes of hunger. By implementing the above strategies, we can make progress towards a world where everyone has access to enough food.\n",
            "Human: \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/MetaPrompt.py\", line 119, in <module>\n",
            "    main(task, max_iters, max_meta_iters)\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/MetaPrompt.py\", line 99, in main\n",
            "    human_input = input()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN AUTOGPT ğŸ¤–"
      ],
      "metadata": {
        "id": "H_aNlq64ANbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Open the /content/Free-AUTO-GPT-with-NO-API/BABYAGI.py and modify or add new tool \n",
        "\"\"\"\n",
        "#ACTUAL TOOL \n",
        "tools = [\n",
        "    web_search, #DuckDuckGoSearchRun()\n",
        "    WriteFileTool(root_dir=\"/data\"),\n",
        "    ReadFileTool(root_dir=\"/data\"),\n",
        "    process_csv,\n",
        "    query_website_tool, playwright()\n",
        "    # HumanInputRun(), # Activate if you want the permit asking for help from the human\n",
        "]\n",
        "\"\"\"\n",
        "!python /content/Free-AUTO-GPT-with-NO-API/AUTOGPT.py --hf_token YourToken --chatgpt_token YourToken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc657529-cef2-4454-c7e8-08e927b637b5",
        "id": "6r5HaCcHANb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the objective of the AI system: (Be realistic!) Write a small report on the current temperature in New York, including the time\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I need to determine the current temperature in New York. I can use a search engine to find this information.\",\n",
            "        \"reasoning\": \"I will use the DuckDuckGo Search command to search for the current temperature in New York. This will provide me with up-to-date information on the current temperature in the city.\",\n",
            "        \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York\\n- Save the result to a file\",\n",
            "        \"criticism\": \"I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\",\n",
            "        \"speak\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"DuckDuckGo Search\",\n",
            "        \"args\": {\n",
            "            \"query\": \"current temperature in New York\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\",\n",
            "        \"reasoning\": \"Using a search engine will allow me to quickly and accurately retrieve the most up-to-date temperature information for New York.\",\n",
            "        \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York\\n- Save the result to a file\",\n",
            "        \"criticism\": \"I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\",\n",
            "        \"speak\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"DuckDuckGo Search\",\n",
            "        \"args\": {\n",
            "            \"query\": \"current temperature in New York\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\",\n",
            "        \"reasoning\": \"This will provide me with up-to-date information on the current temperature in the city.\",\n",
            "        \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York\\n- Save the result to a file\",\n",
            "        \"criticism\": \"I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\",\n",
            "        \"speak\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"DuckDuckGo Search\",\n",
            "        \"args\": {\n",
            "            \"query\": \"current temperature in New York\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I need to write a small report on the current temperature in New York, including the time. I have found the information using the DuckDuckGo Search command. I should write the report in a clear and concise manner, and make sure to include the time and date of the current temperature.\",\n",
            "        \"reasoning\": \"I will use the write_file command to create a text file where I will write the report. I will include the time and date of the current temperature, as well as the source of the information. This will ensure that the report is accurate and can be easily verified. \",\n",
            "        \"plan\": \"- Use the write_file command to create a text file for the report\\n- Write a clear and concise report on the current temperature in New York, including the time and date, and the source of the information\\n- Save the file for later retrieval\",\n",
            "        \"criticism\": \"I need to make sure that the report is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\",\n",
            "        \"speak\": \"I will use the write_file command to create a report on the current temperature in New York, including the time and date of the information and the source of the data.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"write_file\",\n",
            "        \"args\": {\n",
            "            \"file_path\": \"current_temperature_ny.txt\",\n",
            "            \"text\": \"Current temperature in New York as of Fri Apr 28 08:44:23 2023:\\n\\nAccording to AccuWeather, the current temperature in New York is X degrees Fahrenheit. The source of the information is the DuckDuckGo search engine. This report was generated by Tom, Assistant, on Fri Apr 28 08:44:23 2023.\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "Tom: {\"thoughts\": {\"text\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\", \"reasoning\": \"This will provide me with up-to-date information on the current temperature in the city.\", \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York\\n- Save the result to a file\", \"criticism\": \"I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\", \"speak\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"}, \"command\": {\"name\": \"DuckDuckGo Search\", \"args\": {\"query\": \"current temperature in New York\"}}}\n",
            "Assistant Reply: \n",
            "\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I will write a small report on the current temperature in New York, including the time.\",\n",
            "        \"reasoning\": \"This will fulfill the goal of reporting on the current temperature in New York, and also provide a concise report on the time of the report, allowing for easy reference in the future.\",\n",
            "        \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York. \\n- Extract the relevant information from the search results. \\n- Use the write_file command to save the report to a file.\",\n",
            "        \"criticism\": \"I need to make sure that the report is concise and accurate. I should also make sure that the file is saved in a place where it can be easily retrieved later.\",\n",
            "        \"speak\": \"I will write a small report on the current temperature in New York, including the time.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"write_file\",\n",
            "        \"args\": {\n",
            "            \"file_path\": \"temperature_report.txt\",\n",
            "            \"text\": \"As of Fri Apr 28 08:45:23 2023, the current temperature in New York is 65Â°F.\\n\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "I will use the DuckDuckGo Search command to find the current temperature in New York.\n",
            "\n",
            "Reasoning: This will provide me with up-to-date information on the current temperature in the city.\n",
            "\n",
            "Plan: \n",
            "- Use the DuckDuckGo Search command to search for the current temperature in New York\n",
            "- Save the result to a file\n",
            "\n",
            "Criticism: I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\n",
            "\n",
            "Speak: \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"\n",
            "\n",
            "{\"command\": {\"name\": \"DuckDuckGo Search\", \"args\": {\"query\": \"current temperature in New York\"}}, \"thoughts\": {\"text\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\", \"reasoning\": \"This will provide me with up-to-date information on the current temperature in the city.\", \"plan\": \"- Use the DuckDuckGo Search command to search for the current temperature in New York\\n- Save the result to a file\", \"criticism\": \"I need to make sure that the information I find is accurate and up-to-date. I should also make sure that the file is saved in a place where it can be easily retrieved later.\", \"speak\": \"I will use the DuckDuckGo Search command to find the current temperature in New York.\"}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 444, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 828, in read_chunked\n",
            "    self._update_chunk_length()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 758, in _update_chunk_length\n",
            "    line = self._fp.fp.readline()\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/AUTOGPT.py\", line 194, in <module>\n",
            "    agent.run([input(\"Enter the objective of the AI system: (Be realistic!) \")])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/experimental/autonomous_agents/autogpt/agent.py\", line 91, in run\n",
            "    assistant_reply = self.chain.run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 216, in run\n",
            "    return self(kwargs)[self.output_keys[0]]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 116, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 113, in __call__\n",
            "    outputs = self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 57, in _call\n",
            "    return self.apply([inputs])[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 118, in apply\n",
            "    response = self.generate(input_list)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 62, in generate\n",
            "    return self.llm.generate_prompt(prompts, stop)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\", line 107, in generate_prompt\n",
            "    return self.generate(prompt_strings, stop=stop)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\", line 140, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\", line 137, in generate\n",
            "    output = self._generate(prompts, stop=stop)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/llms/base.py\", line 324, in _generate\n",
            "    text = self._call(prompt, stop=stop)\n",
            "  File \"/content/Free-AUTO-GPT-with-NO-API/ChatGPTAPI.py\", line 42, in _call\n",
            "    for data in self.chatbot.ask( prompt ):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/revChatGPT/V1.py\", line 556, in ask\n",
            "    yield from self.post_messages(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/revChatGPT/V1.py\", line 510, in post_messages\n",
            "    yield from self.__send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/revChatGPT/V1.py\", line 368, in __send_request\n",
            "    for line in response.iter_lines():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 865, in iter_lines\n",
            "    for chunk in self.iter_content(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 816, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 624, in stream\n",
            "    for line in self.read_chunked(amt, decode_content=decode_content):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 816, in read_chunked\n",
            "    with self._error_catcher():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 474, in _error_catcher\n",
            "    self._original_response.close()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 419, in close\n",
            "    super().close() # set \"closed\" flag\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 429, in flush\n",
            "    def flush(self):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN CAMEL with Streamlit.io ğŸª"
      ],
      "metadata": {
        "id": "9y5lqAosD6xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrgp7pCcEFWw",
        "outputId": "168e898f-4b3f-4e8d-f9b9-f20604b20a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.069s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/Free-AUTO-GPT-with-NO-API/Camel.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff51c72-49b3-4718-b1f0-526f4bddcd0d",
        "id": "BU5tujDCD6x3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.929s\n",
            "your url is: https://seven-pans-add-35-237-170-21.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN Other Agent or Ddevelop your own Agent ğŸ‘¨â€ğŸ’» ğŸ§‘â€ğŸ’»"
      ],
      "metadata": {
        "id": "Y6CV8XNvLNOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for available AGENT\n",
        "!ls /content/Free-AUTO-GPT-with-NO-API/OtherAgent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa804a3c-2a77-43c7-d010-e112fc347170",
        "id": "1BhJMiSlLNOh"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csvAgent.py  customAgent.py  FreeLLM  pythonAgent.py  startup.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Free-AUTO-GPT-with-NO-API/OtherAgent/csvAgent.py --chatgpt_token YourToken"
      ],
      "metadata": {
        "id": "TU5w982hLNOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}